{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c13ee5b",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier ‚Äî Optimized (SMOTE + GridSearchCV)\n",
    "\n",
    "**Final: Wide (accurate but slower) GridSearchCV with SMOTE**\n",
    "\n",
    "This notebook re-creates the training pipeline used in `Model_Phase3.ipynb`:\n",
    "- SMOTE oversampling on the training set\n",
    "- GridSearchCV with a wide parameter grid (accurate but slower)\n",
    "- Full evaluation and model saving\n",
    "\n",
    "> Make sure `data.csv` is in the same folder and replace `target` with your label column name if different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load dataset\n",
    "# Make sure data.csv is the same dataset used originally.\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(\"Data shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Separate features and target\n",
    "# Replace 'target' with the actual target column name if different.\n",
    "TARGET_COL = 'target'\n",
    "X = data.drop(TARGET_COL, axis=1)\n",
    "y = data[TARGET_COL]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99191278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Train / Test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"Train distribution:\", np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b96602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Setup pipeline: SMOTE -> Scaler -> GradientBoostingClassifier\n",
    "smote = SMOTE(random_state=42)\n",
    "scaler = StandardScaler()\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('smote', smote),\n",
    "    ('scaler', scaler),\n",
    "    ('gb', gb)\n",
    "])\n",
    "\n",
    "# We'll search hyperparameters for the 'gb' step using GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Wide parameter grid for accurate (but slower) search\n",
    "param_grid = {\n",
    "    'gb__n_estimators': [100, 200, 300, 500],\n",
    "    'gb__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'gb__max_depth': [3, 4, 5, 6],\n",
    "    'gb__subsample': [0.6, 0.8, 1.0],\n",
    "    'gb__min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "print(\"Grid sizes (approx):\", \n",
    "      len(param_grid['gb__n_estimators']) * len(param_grid['gb__learning_rate']) *\n",
    "      len(param_grid['gb__max_depth']) * len(param_grid['gb__subsample']) *\n",
    "      len(param_grid['gb__min_samples_leaf'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) GridSearchCV (accurate but slower)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',  # optimize for balanced F1 across classes\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Run the grid search (this may take a long time)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest params:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\nBest CV score (f1_macro):\", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Evaluate on the test set\n",
    "# The pipeline includes SMOTE so the fitted pipeline has already resampled inside CV.\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else None\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='binary' if len(np.unique(y))==2 else 'macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, average='binary' if len(np.unique(y))==2 else 'macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='binary' if len(np.unique(y))==2 else 'macro', zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "print(\"‚úÖ Optimized Gradient Boosting (with SMOTE + GridSearchCV)\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "if roc_auc is not None:\n",
    "    print(f\"ROC-AUC  : {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nüîç Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix - Optimized Gradient Boosting\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10) ROC curve\n",
    "if y_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc_val = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_val:.4f})')\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Optimized Gradient Boosting')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Feature importance (from the 'gb' step)\n",
    "# Extract the GradientBoostingClassifier inside the pipeline\n",
    "gb_step = best_model.named_steps['gb']\n",
    "importances = pd.Series(gb_step.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "importances.head(20).plot(kind='bar')\n",
    "plt.title(\"Top 20 Feature Importances - Optimized Gradient Boosting\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 12) Save the best pipeline/model\n",
    "joblib.dump(best_model, \"gradient_boosting_optimized_pipeline.pkl\")\n",
    "print(\"\\nüíæ Saved optimized pipeline as 'gradient_boosting_optimized_pipeline.pkl'\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
